{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termextractを用いたキーワード抽出と重要度計算処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import termextract.japanese_plaintext\n",
    "import termextract.core\n",
    "from janome.tokenizer import Tokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ストップワードリストに新しい単語を追加\n",
    "new_stopwords = []\n",
    "for word in new_stopwords:\n",
    "    nlp.vocab[word].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいストップワードを追加\n",
    "ignore_words = termextract.japanese_plaintext.IGNORE_WORDS\n",
    "ignore_words.update(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_important_terms_with_scores(text, limit=5):\n",
    "    # TermExtractで重要語を抽出\n",
    "    frequency = termextract.japanese_plaintext.cmp_noun_dict(text)\n",
    "    lr = termextract.core.score_lr(frequency,\n",
    "                                   ignore_words=ignore_words,  # 更新されたストップワードリストを使用\n",
    "                                   lr_mode=1, average_rate=1)\n",
    "    term_imp = termextract.core.term_importance(frequency, lr)\n",
    "\n",
    "    # 重要語をスコア順にソートして返す\n",
    "    important_terms = sorted(term_imp.items(), key=lambda x: x[1], reverse=True)\n",
    "    # 上位 limit 個の用語とそのスコアを返す\n",
    "    return important_terms[:limit]\n",
    "\n",
    "# '目次' と '商品紹介' のカラムを処理\n",
    "df['processed_紹介文'] = df['商品紹介'].astype(str).apply(extract_important_terms)\n",
    "df['processed_目次'] = df['目次'].astype(str).apply(extract_important_terms)\n",
    "\n",
    "\n",
    "# 結果を表示（例）\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_important_terms_with_scores(text, limit=5):\n",
    "    # TermExtractで重要語を抽出\n",
    "    frequency = termextract.japanese_plaintext.cmp_noun_dict(text)\n",
    "    lr = termextract.core.score_lr(frequency,\n",
    "                                   ignore_words=ignore_words,  # 更新されたストップワードリストを使用\n",
    "                                   lr_mode=1, average_rate=1)\n",
    "    term_imp = termextract.core.term_importance(frequency, lr)\n",
    "\n",
    "    # 重要語をスコア順にソートして返す\n",
    "    important_terms = sorted(term_imp.items(), key=lambda x: x[1], reverse=True)\n",
    "    # 上位 limit 個の用語とそのスコアを返す\n",
    "    return important_terms[:limit]\n",
    "\n",
    "# '目次' と '商品紹介' のカラムを処理\n",
    "df['processed_紹介文'] = df['商品紹介'].astype(str).apply(extract_important_terms_with_scores)\n",
    "df['processed_目次'] = df['目次'].astype(str).apply(extract_important_terms_with_scores)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
